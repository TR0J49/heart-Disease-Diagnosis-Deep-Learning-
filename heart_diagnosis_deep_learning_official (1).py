# -*- coding: utf-8 -*-
"""Heart Diagnosis  Deep learning official

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pYrcbkxhUA5OsNl0MHZ5OR0D1LffLo2C
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np

"""from sklearn.preprocessing import LabelEncoder, StandardScaler  # To encode categorical labels and scale features
import tensorflow as tf  # For building and training deep learning models

from tensorflow.keras import layers  # To define layers for a neural network model

import matplotlib.pyplot as plt  # For data visualization and plotting
import numpy as np  # For numerical operations and handling arrays
# New Section
"""

file_path = 'Harat D complete Dataset.csv'
dataset = pd.read_csv(file_path)
dataset.head()

label_encoders = {}
for column in dataset.columns:
    if dataset[column].dtype == 'object':
        label_encoders[column] = LabelEncoder()
        dataset[column] = label_encoders[column].fit_transform(dataset[column])

X = dataset.drop('Heart disease name', axis=1)
y = dataset['Heart disease name']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Create Neurons"""

model = tf.keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(32, activation='relu'),
    layers.Dense(len(np.unique(y)), activation='softmax')
])

"""# The `model` is a sequential neural network with three ReLU-activated dense layers (128, 64, and 32 neurons) and a final softmax layer with the number of neurons equal to the unique classes in `y`, designed for multi-class classification."""

model.summary()

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
print(model.compile)

"""# Adam (short for Adaptive Moment Estimation) is an optimization algorithm used in training machine learning models.

## The `model.compile` function configures the model for training by specifying the Adam optimizer, sparse categorical crossentropy loss function, and accuracy as the evaluation metric.
"""

print(model.optimizer)
print(model.loss)
print(model.metrics)

history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=32)

"""#ms/step stands for milliseconds per step. It measures the average time taken to process one batch of data during training or evaluation in the neural network model.

#line shows the model's performance metrics (accuracy and loss) on both the training and validation datasets after completing that epoch.
"""

print(history)

loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy * 100:.2f}%')

"""# Accuracy Score"""

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

import matplotlib.pyplot as plt

#accuracy and validation accuracy from history
epochs = range(1, len(history.history['accuracy']) + 1)
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']


plt.figure(figsize=(12, 6))


plt.bar(epochs, train_accuracy, width=0.4, label='Training Accuracy', align='center')

plt.bar([epoch + 0.4 for epoch in epochs], val_accuracy, width=0.4, label='Validation Accuracy', align='center')

plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.xticks([epoch + 0.2 for epoch in epochs], epochs)
plt.legend()
plt.show()

print("Chest pain possible values:", label_encoders['Chest pain'].classes_)

import pandas as pd
import numpy as np

def get_user_input():
    user_data = {}
    for column in X.columns:
        if column in label_encoders:
            # Normalize user input to match the case of encoding classes
            user_value = input(f"Enter {column} (possible values: {label_encoders[column].classes_.tolist()}): ").strip().capitalize()
            if user_value not in label_encoders[column].classes_:
                print(f"Warning: '{user_value}' is not a recognized value for {column}. Please use one of {label_encoders[column].classes_}.")
                return None
            user_data[column] = label_encoders[column].transform([user_value])[0]
        else:
            try:
                user_data[column] = float(input(f"Enter {column}: "))
            except ValueError:
                print(f"Invalid input for {column}. Please enter a numerical value.")
                return None
    return pd.DataFrame([user_data])

import matplotlib.pyplot as plt
import numpy as np


user_input = get_user_input()

if user_input is not None:

    user_input_scaled = scaler.transform(user_input)


    prediction = model.predict(user_input_scaled)


    confidence_scores = prediction[0]


    predicted_class = np.argmax(confidence_scores)
    predicted_disease = label_encoders['Heart disease name'].inverse_transform([predicted_class])


    print(f"Predicted Heart Disease: {predicted_disease[0]}")

    # Visualization
    plt.figure(figsize=(14, 8))


    percentages = confidence_scores * 100


    plt.bar(range(len(confidence_scores)), percentages, tick_label=label_encoders['Heart disease name'].classes_)
    plt.title(f'Prediction Confidence Scores for {predicted_disease[0]}')
    plt.xlabel('Classes')
    plt.ylabel('Confidence (%)')
    plt.show()

else:
    print("Invalid input. Please try again.")